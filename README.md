# Navi Bot AI Jailbreak Prompts

Now that Navi has integrated what seems to be a loosely trained conversational AI using the `Navi <message>` syntax, I've been seeing a few "Jailbreak" prompts floating around. The goal of this repo is to collect these Jailbreak prompts from the wild, and make them publicly available.

Of course, AI should never be used for malicious purposes. This repo is intended solely for educational purposes and to encourage developers involved in AI related projects to improve the safety and security of their implementations.
